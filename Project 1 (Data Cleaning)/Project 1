# 1. Data Cleaning Project: Layoffs Dataset

## Overview
This project focuses on cleaning a raw dataset of company layoffs using SQL. The goal was to ensure data consistency, remove duplicates, handle null values, and standardize formats for accurate analysis.

## Key Steps
1. **Duplicate Raw Data**: Created a backup of the raw data to prevent data loss.
2. **Remove Duplicates**: Identified and removed duplicate records using `ROW_NUMBER()` and CTEs.
3. **Standardize Data**:
   - Removed leading/trailing whitespaces.
   - Consolidated similar categories (e.g., "Crypto" and "Cryptocurrency" â†’ "Crypto").
   - Fixed inconsistent country names (e.g., "United States" vs. "United States.").
   - Converted date strings to `DATE` format using `STR_TO_DATE`.
4. **Handle Null/Blank Values**:
   - Populated missing industry values based on other rows for the same company.
   - Removed records with null values in `total_laid_off` and `percentage_laid_off`.
5. **Remove Unnecessary Columns**: Deleted temporary columns like `row_num` after cleaning.

## Tools Used
- **SQL**: For data cleaning and transformation.
- **MySQL Workbench**: For executing queries and managing the database.

## Project Structure
- `data/`: Contains the raw and cleaned datasets (`layoffs.csv` and `layoffs_cleaned.csv`).
- `scripts/`: Contains the SQL script (`data_cleaning.sql`).

## Where I got my data from: 
https://github.com/AlexTheAnalyst/MySQL-YouTube-Series/blob/main/layoffs.csv
